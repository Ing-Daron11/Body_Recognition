{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090812c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.3-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\daron\\onedrive\\escritorio\\semestre vii\\ia\\body_recognition\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.2-cp310-cp310-win_amd64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daron\\onedrive\\escritorio\\semestre vii\\ia\\body_recognition\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.2.1-cp310-cp310-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daron\\onedrive\\escritorio\\semestre vii\\ia\\body_recognition\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.0-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Using cached scikit_learn-1.7.0-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "Using cached xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "Using cached matplotlib-3.10.3-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.2-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 6.3 MB/s eta 0:00:00\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 8.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/12.9 MB 7.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.9 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.9 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.9/12.9 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.9 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 6.7 MB/s eta 0:00:00\n",
      "Using cached pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, xgboost, scikit-learn, matplotlib, seaborn\n",
      "\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [tzdata]\n",
      "   -- -------------------------------------  1/17 [tzdata]\n",
      "   -- -------------------------------------  1/17 [tzdata]\n",
      "   -- -------------------------------------  1/17 [tzdata]\n",
      "   ------- --------------------------------  3/17 [pyparsing]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ---------------- -----------------------  7/17 [joblib]\n",
      "   ---------------- -----------------------  7/17 [joblib]\n",
      "   ---------------- -----------------------  7/17 [joblib]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ------------------ ---------------------  8/17 [fonttools]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ----------------------- ---------------- 10/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ------------------------- -------------- 11/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [contourpy]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   ------------------------------ --------- 13/17 [xgboost]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ------------------------------------- -- 16/17 [seaborn]\n",
      "   ------------------------------------- -- 16/17 [seaborn]\n",
      "   ------------------------------------- -- 16/17 [seaborn]\n",
      "   ---------------------------------------- 17/17 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.2 joblib-1.5.1 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.2.6 pandas-2.3.0 pillow-11.2.1 pyparsing-3.2.3 pytz-2025.2 scikit-learn-1.7.0 scipy-1.15.3 seaborn-0.13.2 threadpoolctl-3.6.0 tzdata-2025.2 xgboost-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn xgboost matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1469e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m         test_videos\u001b[38;5;241m.\u001b[39mextend(v_test)\n\u001b[0;32m     43\u001b[0m remaining_videos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(videos_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(train_videos) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(test_videos)\n\u001b[1;32m---> 44\u001b[0m v_train, v_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremaining_videos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m train_videos\u001b[38;5;241m.\u001b[39mextend(v_train)\n\u001b[0;32m     46\u001b[0m test_videos\u001b[38;5;241m.\u001b[39mextend(v_test)\n",
      "File \u001b[1;32mc:\\Users\\daron\\OneDrive\\Escritorio\\Semestre VII\\IA\\Body_Recognition\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\daron\\OneDrive\\Escritorio\\Semestre VII\\IA\\Body_Recognition\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2916\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2918\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2919\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2921\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\daron\\OneDrive\\Escritorio\\Semestre VII\\IA\\Body_Recognition\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2496\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2500\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2503\u001b[0m     )\n\u001b[0;32m   2505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(\"../data_set_videos/dataset_final.csv\")\n",
    "\n",
    "# Asegúrate de tener la columna 'video_id'\n",
    "assert 'video_id' in df.columns, \"Falta la columna video_id en el CSV\"\n",
    "\n",
    "# Codificar etiquetas\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])\n",
    "\n",
    "# Eliminar filas con demasiados ceros\n",
    "umbral_ceros = 0.3\n",
    "porcentaje_ceros = (df == 0).sum(axis=1) / df.shape[1]\n",
    "df = df[porcentaje_ceros < umbral_ceros]\n",
    "\n",
    "# Split estratificado por acción (asegura al menos un video por acción en train)\n",
    "videos_info = df[['video_id', 'label']].drop_duplicates()\n",
    "train_videos = []\n",
    "test_videos = []\n",
    "\n",
    "for action in videos_info['label'].unique():\n",
    "    vids = videos_info[videos_info['label'] == action]['video_id'].tolist()\n",
    "    if len(vids) == 1:\n",
    "        train_videos.append(vids[0])\n",
    "    else:\n",
    "        v_train, v_test = train_test_split(vids, test_size=0.3, random_state=42)\n",
    "        train_videos.extend(v_train)\n",
    "        test_videos.extend(v_test)\n",
    "\n",
    "remaining_videos = set(videos_info['video_id']) - set(train_videos) - set(test_videos)\n",
    "if len(remaining_videos) >= 2:\n",
    "    v_train, v_test = train_test_split(list(remaining_videos), test_size=0.3, random_state=42)\n",
    "    train_videos.extend(v_train)\n",
    "    test_videos.extend(v_test)\n",
    "elif len(remaining_videos) == 1:\n",
    "    train_videos.extend(list(remaining_videos))\n",
    "# Si es 0, no haces nada\n",
    "\n",
    "train_df = df[df['video_id'].isin(train_videos)]\n",
    "test_df = df[df['video_id'].isin(test_videos)]\n",
    "\n",
    "# Features y labels\n",
    "X_train = train_df.drop(columns=[\"label\", \"frame\", \"video_id\", \"label_encoded\"])\n",
    "X_test = test_df.drop(columns=[\"label\", \"frame\", \"video_id\", \"label_encoded\"])\n",
    "y_train = train_df[\"label_encoded\"]\n",
    "y_test = test_df[\"label_encoded\"]\n",
    "\n",
    "# Escalar features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=0.95, svd_solver='full')\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Modelos a evaluar\n",
    "modelos = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=60, random_state=24),\n",
    "    \"SVM\": SVC(kernel='rbf', probability=True),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\n Entrenando {nombre}...\")\n",
    "    modelo.fit(X_train_pca, y_train)\n",
    "\n",
    "    y_pred = modelo.predict(X_test_pca)\n",
    "\n",
    "    train_acc = modelo.score(X_train_pca, y_train)\n",
    "    test_acc = modelo.score(X_test_pca, y_test)\n",
    "\n",
    "    print(f\"\\n Resultados para {nombre}:\")\n",
    "    print(f\" Accuracy en entrenamiento: {train_acc:.2f}\")\n",
    "    print(f\" Accuracy en prueba:       {test_acc:.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "    # Matriz de confusión\n",
    "    plt.figure(figsize=(8,6))\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=range(len(le.classes_)))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f\"Matriz de Confusión - {nombre}\")\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Validación cruzada por video (GroupKFold)\n",
    "    print(f\"\\nValidación cruzada por video para {nombre}:\")\n",
    "    X = df.drop(columns=[\"label\", \"frame\", \"video_id\", \"label_encoded\"])\n",
    "    y = df[\"label_encoded\"]\n",
    "    groups = df[\"video_id\"]\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    scores = cross_val_score(modelo, X_pca, y, cv=gkf.split(X_pca, y, groups), scoring='accuracy')\n",
    "    print(f\"Scores por fold: {scores}\")\n",
    "    print(f\"Media: {np.mean(scores):.4f} | Desviación estándar: {np.std(scores):.4f}\")\n",
    "\n",
    "    # Guardar el modelo\n",
    "    joblib.dump(modelo, f\"modelo_{nombre}.pkl\")\n",
    "\n",
    "# Guardar preprocesadores y encoder\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(pca, \"pca.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
