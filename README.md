
# Proyecto Final - Inteligencia Artificial I (2025-1)

  

**Universidad ICESI**

IngenierÃ­a de Sistemas

  

## Integrantes

- Daron Mercado

- Santiago Arboleda

- Miguel MartÃ­nez

  

## ğŸ¯ Objetivo

Desarrollar un sistema de software capaz de analizar y clasificar, en tiempo real, actividades humanas especÃ­ficas (caminar hacia la cÃ¡mara, caminar de regreso, girar, sentarse y ponerse de pie) mediante el seguimiento de movimientos articulares extraÃ­dos de video en vivo.

  

## ğŸ“¥ Entradas

-  **Video en tiempo real** 

  

## ğŸ“¤ Salidas

-  **ClasificaciÃ³n de actividad** en tiempo real (etiquetas: `walking_towards`, `walking_away`, `turning`, `sitting`, `standing_up`).

-  **MÃ©tricas posturales**: Ã¡ngulos de rodilla, cadera y hombro.

-  **Streaming MJPEG** con overlay de landmarks y resultados.

  

## ğŸ”§ Herramientas y TecnologÃ­as

-  **MediaPipe Pose** para extracciÃ³n de 33 landmarks articulares.

-  **Python 3.10**, **OpenCV**, **scikit-learn**, **XGBoost**.

-  **Flask** para API RESTful

-  **StandardScaler** e **Incremental PCA** para preprocesamiento en lÃ­nea.

- Herramientas de anotaciÃ³n: **CVAT**, **LabelStudio**.

  

## ğŸ“‚ Estructura del repositorio

Body_Recognition/

â”œâ”€ data/ # Videos originales y frames extraÃ­dos

â”œâ”€ notebooks/ # EDA y experimentos preliminares

â”œâ”€ src/

â”‚ â”œâ”€ acquisition.py # Captura de video y streaming

â”‚ â”œâ”€ preprocessing.py # Filtrado, normalizaciÃ³n y PCA

â”‚ â”œâ”€ features.py # CÃ¡lculo de Ã¡ngulos y features derivadas

â”‚ â”œâ”€ train.py # Entrenamiento y validaciÃ³n de modelos

â”‚ â””â”€ app.py # Servidor Flask (/video_feed, /predict)

â”œâ”€ models/ # Modelos serializados (.joblib)

â”œâ”€ Dockerfile # ContenerizaciÃ³n de la aplicaciÃ³n

â”œâ”€ requirements.txt # Dependencias Python

â””â”€ README.md # DocumentaciÃ³n del proyecto

  

## ğŸš€ MetodologÃ­a (CRISP-DM adaptado)

1.  **ComprensiÃ³n del problema**

- Requisitos: accuracy â‰¥ 0.90, latencia < 100 ms, portabilidad.

- RevisiÃ³n bibliogrÃ¡fica y definiciÃ³n de entregables semanales.

2.  **RecolecciÃ³n y AnotaciÃ³n de Datos**

- 80 clips (20 por actividad) grabados a 60 fps, fondo neutro e iluminaciÃ³n homogÃ©nea.

- AnotaciÃ³n de ventanas de N = 30 frames con etiquetas uniformes.

3.  **ExtracciÃ³n de Landmarks**

- MediaPipe Pose: 33 puntos 3D + visibilidad por fotograma.

- Suavizado exponencial y descarte de visibilidad < 0.5.

4.  **GeneraciÃ³n de Features**

- Coordenadas normalizadas con StandardScaler.

- CÃ¡lculo de Ã¡ngulos biomecÃ¡nicos (rodilla, cadera).

5.  **ReducciÃ³n de Dimensionalidad**

- PCA: 10 componentes principales (95 % varianza).

- Incremental PCA para escaneo en tiempo real.

6.  **Entrenamiento y EvaluaciÃ³n**

- Modelos: SVM, Random Forest, XGBoost con GridSearchCV.

- DivisiÃ³n 70/30 train-test, validaciÃ³n cruzada estratificada.

- MÃ©tricas: accuracy, precision, recall, F1-score.

7.  **Despliegue e Inferencia**

- API Flask con endpoints `/video_feed` (MJPEG) y `/predict` (JSON).

- VotaciÃ³n ponderada de modelos segÃºn F1-score.

- Docker para asegurar replicabilidad.

## ğŸ“º Demo

<video controls width="640" poster="templates/demo/turn.png">
  <source src="templates/demo/demostration.mp4" type="video/mp4">
  Tu navegador no soporta reproducciÃ³n de video.
</video>

â–¶ï¸ Ver demostraciÃ³n en video


https://github.com/user-attachments/assets/a6d88c8c-8c68-47be-8255-a8db5b4a3abc



### ğŸ¬ Capturas de pantalla

<p float="left">
  <img src="templates/demo/turn.png" alt="Girar" width="320" />
  <img src="templates/demo/sitting.png" alt="Sentado" width="320" />
</p>


  

## ğŸ“Š Resultados Principales

| Modelo | Accuracy (test) | F1-macro |
|---------------|-----------------|----------|
| **SVM** | 88 % | 0.88 |
| **Random Forest** | 99% | 0.99 |
| **XGBoost** | 99% | 0.99 |

  

>  *El XGBoost mostrÃ³ el mejor balance entre precisiÃ³n y generalizaciÃ³n en condiciones variables de captura.*

  

## ğŸ”­ Trabajo Futuro

- Aumentar y diversificar el dataset (sujetos, escenarios, condiciones lumÃ­nicas).

- Evaluar arquitecturas LSTM/GRU para capturar dependencias temporales.

- Integrar sensores IMU para enriquecer datos de movimiento.

- Desplegar en edge devices (Jetson Nano, Raspberry Pi + TPU).

- Explorar aprendizaje continuo y adaptaciÃ³n de dominio.

  

## ğŸ§ª Entregables

-  **Semana 12:** MetodologÃ­a, mÃ©tricas, EDA y estrategia de expansiÃ³n de datos.

-  **Semana 14:** Preprocesamiento, PCA, entrenamiento inicial y resultados preliminares.

-  **Semana 17:** Sistema final desplegado, evaluaciÃ³n completa y video de presentaciÃ³n.

  

## ğŸ”— Enlaces

-  **PresentaciÃ³n:** https://drive.google.com/drive/folders/1AR6uxIySGLWzLHBRTTxHWf70CJF1OT5l

-  **Repositorio:** https://github.com/Ing-Daron11/Body_Recognition
